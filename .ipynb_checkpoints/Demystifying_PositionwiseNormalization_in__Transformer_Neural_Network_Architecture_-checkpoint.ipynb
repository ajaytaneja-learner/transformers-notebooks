{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-UOpw89xaB0U"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class PositionwiseNormalization():\n",
    "    \"\"\"\n",
    "\n",
    "    This is a class to carry out PositionwiseNormalization along the feature\n",
    "    dimension of the word embeddings. It is done to ensure that the values\n",
    "    are consistent and hence do not affect upstream process in feed forward\n",
    "    network.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, parameters_shape, eps=1e-5):\n",
    "        \"\"\"\n",
    "        The constructor (__init__) initializes the PositionwiseNormalization\n",
    "        object with the following parameters:\n",
    "\n",
    "        parameters_shape : integer\n",
    "            This is the shape of the parameters (gamma and beta) used for\n",
    "            normalization. It specifies the dimensions over which normalization\n",
    "            will be applied.\n",
    "\n",
    "        eps : decimal\n",
    "            This is a small constant added to the denominator to prevent\n",
    "            division by zero (avoiding numerical instability).\n",
    "\n",
    "        Inside the constructor, the class initializes two learnable parameters:\n",
    "\n",
    "        self.gamma:\n",
    "            It's initialized as a learnable parameter with ones,\n",
    "            meaning it starts with no scaling (identity operation).\n",
    "\n",
    "        self.beta:\n",
    "            It's initialized as a learnable parameter with zeros,\n",
    "            meaning it starts with no shift.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.parameters_shape=parameters_shape\n",
    "        self.eps=eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
    "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        The forward function is where the actual Layer Normalization is\n",
    "        applied to the input tensor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input : tensor\n",
    "            This is a tensor of word embeddings\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out   : tensor\n",
    "            This is a tensor of normalized output\n",
    "        \"\"\"\n",
    "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
    "        mean = inputs.mean(dim=dims, keepdim=True)\n",
    "        print(f\"Mean \\n ({mean.size()}): \\n {mean}\")\n",
    "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
    "        std = (var + self.eps).sqrt()\n",
    "        print(f\"Standard Deviation \\n ({std.size()}): \\n {std}\")\n",
    "        y = (inputs - mean) / std\n",
    "        print(f\"y \\n ({y.size()}) = \\n {y}\")\n",
    "        out = self.gamma * y  + self.beta\n",
    "        print(f\"out \\n ({out.size()}) = \\n {out}\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "roxxdo7_a15L"
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "sentence_length = 5\n",
    "embedding_dim = 3\n",
    "inputs = torch.randn(sentence_length, batch_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "53trQkjxa5zr"
   },
   "outputs": [],
   "source": [
    "check = inputs.size()[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5JVPMCqJbRMN",
    "outputId": "aa861c23-05d3-4be1-a899-3bd7c07bc0a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EnZFLwasQFMM"
   },
   "outputs": [],
   "source": [
    "positionwise_norm = PositionwiseNormalization(inputs.size()[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lRn3KNZIQZJc",
    "outputId": "d661c168-d690-497e-ac93-c60027823f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean \n",
      " (torch.Size([5, 3, 1])): \n",
      " tensor([[[ 0.1668],\n",
      "         [-0.2364],\n",
      "         [ 0.1095]],\n",
      "\n",
      "        [[ 0.5149],\n",
      "         [-0.7531],\n",
      "         [ 0.3106]],\n",
      "\n",
      "        [[-0.9827],\n",
      "         [ 0.1498],\n",
      "         [ 0.5688]],\n",
      "\n",
      "        [[-0.8799],\n",
      "         [-0.0753],\n",
      "         [ 0.2611]],\n",
      "\n",
      "        [[-0.0795],\n",
      "         [ 0.2803],\n",
      "         [-0.2529]]])\n",
      "Standard Deviation \n",
      " (torch.Size([5, 3, 1])): \n",
      " tensor([[[1.1969],\n",
      "         [0.5374],\n",
      "         [2.0000]],\n",
      "\n",
      "        [[0.5590],\n",
      "         [0.2884],\n",
      "         [0.1639]],\n",
      "\n",
      "        [[0.6091],\n",
      "         [0.3854],\n",
      "         [0.7997]],\n",
      "\n",
      "        [[0.8282],\n",
      "         [0.6363],\n",
      "         [1.2907]],\n",
      "\n",
      "        [[0.7299],\n",
      "         [0.5181],\n",
      "         [0.5707]]])\n",
      "y \n",
      " (torch.Size([5, 3, 3])) = \n",
      " tensor([[[ 1.3403, -1.0609, -0.2794],\n",
      "         [ 1.2630, -1.1825, -0.0805],\n",
      "         [ 0.2595, -1.3337,  1.0742]],\n",
      "\n",
      "        [[ 1.3953, -0.4984, -0.8970],\n",
      "         [ 1.3147, -0.2062, -1.1085],\n",
      "         [ 1.3893, -0.4670, -0.9223]],\n",
      "\n",
      "        [[ 1.4082, -0.8169, -0.5912],\n",
      "         [-0.4547,  1.3870, -0.9323],\n",
      "         [-1.3610,  1.0133,  0.3477]],\n",
      "\n",
      "        [[ 0.9770,  0.3970, -1.3740],\n",
      "         [ 0.9696, -1.3763,  0.4067],\n",
      "         [ 1.3546, -1.0291, -0.3255]],\n",
      "\n",
      "        [[-0.0426,  1.2455, -1.2029],\n",
      "         [-0.4967, -0.8984,  1.3950],\n",
      "         [-0.4566,  1.3874, -0.9308]]])\n",
      "out \n",
      " (torch.Size([5, 3, 3])) = \n",
      " tensor([[[ 1.3403, -1.0609, -0.2794],\n",
      "         [ 1.2630, -1.1825, -0.0805],\n",
      "         [ 0.2595, -1.3337,  1.0742]],\n",
      "\n",
      "        [[ 1.3953, -0.4984, -0.8970],\n",
      "         [ 1.3147, -0.2062, -1.1085],\n",
      "         [ 1.3893, -0.4670, -0.9223]],\n",
      "\n",
      "        [[ 1.4082, -0.8169, -0.5912],\n",
      "         [-0.4547,  1.3870, -0.9323],\n",
      "         [-1.3610,  1.0133,  0.3477]],\n",
      "\n",
      "        [[ 0.9770,  0.3970, -1.3740],\n",
      "         [ 0.9696, -1.3763,  0.4067],\n",
      "         [ 1.3546, -1.0291, -0.3255]],\n",
      "\n",
      "        [[-0.0426,  1.2455, -1.2029],\n",
      "         [-0.4967, -0.8984,  1.3950],\n",
      "         [-0.4566,  1.3874, -0.9308]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = positionwise_norm.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkPM7lq5QhV6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
